{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UNpEYHwkchy"
      },
      "source": [
        "# 10-714 Final Project: Pre-training with NEEDLE\n",
        "NEEDLE is a self-contained deep learning framework that supports training and inference with a variety of modern neural networks. Throughout this course, we have implemented several different neural network architectures, including feed-forward, convolutional, and recurrent networks. Another key function of this framework is the ability to use pretrained network weights. In this project, we propose to implement the following two features:\n",
        "\n",
        "1. Save and load weights with NEEDLE\n",
        "2. Port external models to a NEEDLE model. In order to support as many frameworks as possible, instead of implementing individual converters for each framework, we will implement a conversion pipeline that takes an ONNX model as input and converts it to a NEEDLE model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l22tr3bUkchz"
      },
      "source": [
        "## 0 Setup\n",
        "Code download: https://drive.google.com/drive/folders/1s_YM-UV2I2bxAAN_zpYRGHm0qk-9p_M1?usp=share_link"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-PyLZI4kchz"
      },
      "source": [
        "## 1 Save/Load weights with NEEDLE\n",
        "In this section, we refer to \"model\" as any architecture that inherit the `ndl.nn.Module` class. The first feature of NEEDLE is the ability to save and load model weights. This process is split into two steps: saving and loading.\n",
        "\n",
        "To save the weights, we simply iterate through all the parameters in the model, create signature for them, and save them to a file. \n",
        "\n",
        "Loading the weights is a bit more complicated, as we need to ensure that the target model has the same architecture as the model from which the weights were saved. We need to compare the signature of the models, and device of the models. If both match, we load the weights corresondingly. Otherwise, we raise an error.\n",
        "\n",
        "Once the signatures have been verified, we can load the weights from the file and assign them to the corresponding parameters in the target model. This ensures that the weights are applied correctly, allowing the model to continue making predictions using the loaded weights.\n",
        "\n",
        "Now we explain the implementation step by step.\n",
        "\n",
        "### Description\n",
        "#### Save weights\n",
        "1. Create a signature for the parameters and the model (i.e., the ndl.nn.Module object). The state_dict() function creates a signature for each parameter and stores them in a dictionary that maps the signature to its corresponding value. The id() function creates a signature for the model that describes its architecture. Note that instead of using the name of each parameter, we manually name the parameters with a counter. This avoids the problem of two models with the same architecture having different names for their parameters.\n",
        "    ```python\n",
        "    def state_dict(self, prefix=\"\"):\n",
        "        \"\"\"Return a dictionary of the module's parameters.\"\"\"\n",
        "        # Create an empty dictionary to store the state of the model\n",
        "        state_dict = {}\n",
        "        # Create a counter for each module's class name\n",
        "        count = Counter()\n",
        "        \n",
        "        # Iterate through all the attributes of the module\n",
        "        for k, v in self.__dict__.items():\n",
        "            # If the attribute is a parameter, add it to the dictionary\n",
        "            if isinstance(v, Parameter):\n",
        "                name = k\n",
        "                state_dict[prefix + name] = v\n",
        "            # If the attribute is a module, increment the counter and add the module and its parameters to the dictionary\n",
        "            elif isinstance(v, Module):\n",
        "                count[v.__class__.__name__] += 1\n",
        "                name = v.__class__.__name__ + '-' + str(count[v.__class__.__name__])\n",
        "                state_dict.update(v.state_dict(prefix + name + \".\"))\n",
        "        return state_dict\n",
        "    ```\n",
        "\n",
        "    ```python\n",
        "    def id(self):\n",
        "        \"\"\"construct a json string that uniquely identifies the module.\"\"\"\n",
        "        # Create a counter for each module's class name\n",
        "        count = Counter()\n",
        "\n",
        "        # Create a dictionary to store the signatures of the module's parameters\n",
        "        signatures = dict()\n",
        "        \n",
        "        # Add the class name of the module to the dictionary\n",
        "        signatures[self.__class__.__name__] = dict()\n",
        "        \n",
        "        # Set the current dictionary to the inner dictionary that was just created\n",
        "        signatures = signatures[self.__class__.__name__]\n",
        "        \n",
        "        # Iterate through the attributes of the module\n",
        "        for k, v in self.__dict__.items():\n",
        "            # If the attribute is a module, increment the counter and add its signature to the dictionary\n",
        "            if isinstance(v, Module):\n",
        "                count[v.__class__.__name__] += 1\n",
        "                name = v.__class__.__name__ + '-' + str(count[v.__class__.__name__])\n",
        "                signatures[name] = v.id()\n",
        "            # If the attribute is a parameter, add its shape to the dictionary\n",
        "            elif isinstance(v, Parameter):\n",
        "                name = k\n",
        "                signatures[name] = v.shape\n",
        "            # If the attribute is a list or tuple, iterate through its elements\n",
        "            # and add the signatures of the modules and parameters to the dictionary\n",
        "            elif isinstance(v, (list, tuple)):\n",
        "                for i, x in enumerate(v):\n",
        "                    if isinstance(x, Module):\n",
        "                        count[x.__class__.__name__] += 1\n",
        "                        name = x.__class__.__name__ + '-' + str(count[x.__class__.__name__])\n",
        "                        signatures[name] = x.id()\n",
        "                    elif isinstance(x, Parameter):\n",
        "                        name = k\n",
        "                        signatures[name] = x.shape\n",
        "        # Return the dictionary containing the signatures of the module's parameters\n",
        "        return signatures\n",
        "    ```\n",
        "\n",
        "2. Save the `state_dict` to a `.npy` file. We also save the `device` of the model.\n",
        "\n",
        "\n",
        "    ```python\n",
        "    def save_state_dict(module, filename):\n",
        "        \"\"\"\n",
        "        Save the state dict of a module to a file.\n",
        "\n",
        "        Args:\n",
        "            module (ndl.nn.Module): The module to save.\n",
        "            filename (str): The file to save to.\n",
        "        \"\"\"\n",
        "        # Create a dictionary to store the state dict and signature of the module\n",
        "        save_dict = {}\n",
        "        save_dict['state_dict'] = module.state_dict()\n",
        "\n",
        "        # Convert the state dict to numpy arrays and store them in the dictionary\n",
        "        for k, v in save_dict['state_dict'].items():\n",
        "            save_dict['state_dict'][k] = v.numpy().astype(np.float32)\n",
        "        # Store the signature of the module in the dictionary\n",
        "        save_dict['signature'] = str(module.id())\n",
        "\n",
        "        # Store the device of the module in the dictionary\n",
        "        save_dict['device'] = str(module.device)\n",
        "\n",
        "        # Save the dictionary to the specified file using numpy\n",
        "        np.save(filename, save_dict)\n",
        "        print(\"Saved state dict to file: {}\".format(filename))\n",
        "    ```\n",
        "\n",
        "#### Load weights\n",
        "Compare the signature of the target model and source model. Then, load the `state_dict` into the model by matching the parameter signatures\n",
        "\n",
        "```python\n",
        "def load_state_dict(module, filename):\n",
        "    \"\"\"\n",
        "    Load the state dict from a file.\n",
        "\n",
        "    Args:\n",
        "        module: (ndl.nn.Module): The module to load the state dict to.\n",
        "        filename (str): The file to load state dict from.\n",
        "    \"\"\"\n",
        "    # Load the dictionary containing the state dict and signature of the module from the file\n",
        "    save_dict = np.load(filename, allow_pickle=True).item()\n",
        "\n",
        "    # Check if the signature of the loaded module matches the saved state dict\n",
        "    assert save_dict['signature'] == str(module.id()), \"Module signature does not match saved state dict\"\n",
        "\n",
        "    # Check if the device of the loaded module matches the saved state dict\n",
        "    assert save_dict['device'] == str(module.device), \"Module device does not match saved state dict\"\n",
        "\n",
        "    # Load the state dict to the module\n",
        "    module.load_state_dict(save_dict['state_dict'])\n",
        "\n",
        "    # Print a message to indicate that the state dict has been loaded from the file\n",
        "    print(\"Loaded state dict from file: {}\".format(filename))\n",
        "```\n",
        "\n",
        "and `module.load_state_dict()` function:\n",
        "\n",
        "```python\n",
        "def load_state_dict(self, state_dict):\n",
        "    \"\"\"\n",
        "    Iterate over the module's parameters and submodules and load the values from the  state_dict.\n",
        "    \n",
        "    Args:\n",
        "        state_dict (dict): A dictionary containing the values to load.\n",
        "    \"\"\"\n",
        "    # Get a dictionary of the module's parameters\n",
        "    this = self.state_dict()\n",
        "    # Iterate through the values in the state_dict\n",
        "    for k, v in state_dict.items():\n",
        "        # If the value is a parameter of the module, set its value to the value from the state_dict\n",
        "        if k in this:\n",
        "            this[k].data = Tensor(NDArray(v, device=self.device), device=self.device, requires_grad=True)\n",
        "        else:\n",
        "            # If the value is not a parameter of the module, raise an error\n",
        "            raise KeyError(\"State dict does not contain key: \" + k)\n",
        "```\n",
        "\n",
        "#### Model Summary\n",
        "As a side product of the above functions, we can also create a model summary function that prints out the model's architecture and the shape of its parameters. This is useful for debugging and understanding the model's architecture. The summary is in the format of a json string. \n",
        "\n",
        "```python\n",
        "def summary(self):\n",
        "    \"\"\"Print a summary of the module.\"\"\"\n",
        "    id = self.id()\n",
        "    pp = pprint.PrettyPrinter(indent=2)\n",
        "    pp.pprint(id)\n",
        "    return json.dumps(id)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKhigvqokch1"
      },
      "source": [
        "### Demo\n",
        "####  Save/Load weights\n",
        "In this section, we demonstrate NEEDLE's save/load weights functionality with live code blocks. Here we use a ResNet9 model we developed during HW4, but in theory any model is supported as the save/load are implemented for the base `ndl.nn.Module` class.\n",
        "\n",
        "We start by importing the necessary libraries and defining the ResNet9 model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mdQByAWkch1",
        "outputId": "25674870-7bcf-4d9d-d84c-561e6fa46630"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "<module 'needle.backend_ndarray' from './python/needle/backend_ndarray/__init__.py'>\n"
          ]
        }
      ],
      "source": [
        "from apps.models import ResNet9\n",
        "import numpy as np \n",
        "import needle as ndl\n",
        "from needle.autograd import Tensor\n",
        "\n",
        "model = ResNet9(device=ndl.cpu())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SFlpKKmkch3"
      },
      "source": [
        "The saving of the model's weights is done by calling the `ndl.save_state_dict()` function. We use the numpy object array as a medium of saved data. Note that both the model weights and device information are saved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSQ1Sfyzkch3",
        "outputId": "58101d5c-b45a-40a4-e3c6-58a2a3e6584a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved state dict to file: weights.npy\n"
          ]
        }
      ],
      "source": [
        "ndl.save_state_dict(model, 'weights.npy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swefFPyUkch3"
      },
      "source": [
        "To demonstrate the loading of the model's weights, we create a new model and load the saved weights into it. We then compare the weights of the two models to show that they are the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwIJzaDtkch3"
      },
      "outputs": [],
      "source": [
        "new_model = ResNet9(device=ndl.cpu())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UkV_-WTkch4"
      },
      "source": [
        "Before loading the weights, `model` and `new_model` have different weights, thus different output. Let's test that out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-5O3GAOkch4",
        "outputId": "09746dc1-540c-47c4-de3f-6ed0362b538a"
      },
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "As expected, the two models have different outputs",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m x \u001b[39m=\u001b[39m Tensor(np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandn(\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m32\u001b[39m, \u001b[39m32\u001b[39m)\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32), device\u001b[39m=\u001b[39mndl\u001b[39m.\u001b[39mcpu())\n\u001b[0;32m----> 3\u001b[0m \u001b[39massert\u001b[39;00m np\u001b[39m.\u001b[39mallclose(model(x)\u001b[39m.\u001b[39mnumpy(), new_model(x)\u001b[39m.\u001b[39mnumpy()), \u001b[39m'\u001b[39m\u001b[39mAs expected, the two models have different outputs\u001b[39m\u001b[39m'\u001b[39m\n",
            "\u001b[0;31mAssertionError\u001b[0m: As expected, the two models have different outputs"
          ]
        }
      ],
      "source": [
        "x = Tensor(np.random.randn(1, 3, 32, 32).astype(np.float32), device=ndl.cpu())\n",
        "\n",
        "assert np.allclose(model(x).numpy(), new_model(x).numpy()), 'As expected, the two models have different outputs'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bWYqJuakch4"
      },
      "source": [
        "Now we load the weights we just saved into `new_model`. We can see that the weights of `model` and `new_model` are the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zynvFVG_kch4",
        "outputId": "d313a7fe-49e3-4190-e6b1-8ad644c61818"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded state dict from file: weights.npy\n",
            "Loading Success! The models now have same outputs\n"
          ]
        }
      ],
      "source": [
        "ndl.load_state_dict(new_model, 'weights.npy')\n",
        "\n",
        "assert np.allclose(model(x).numpy(), new_model(x).numpy()), 'The two models have different outputs'\n",
        "\n",
        "print('Loading Success! The models now have same outputs')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IP-xilzWkch4"
      },
      "source": [
        "As expected, they now have the same output.\n",
        "\n",
        "But things could get complicated if we have various models of different architecture. In these cases we want to prevent the model from loading weights that are not compatible with its architecture. We have set up a check to ensure that the model's signature matches the signature of the saved weights. If the signatures do not match, an error will be raised. We also prevent the model from loading weights that are saved on a different device.\n",
        "\n",
        "Here we define a `ResNet9_2` model, which is very similar to `ResNet9` but has different shapes in some layers. We then try to load the weights of `ResNet9` into `ResNet9_2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dz5vLxLEkch5",
        "outputId": "2ce43770-4020-42d1-b9ca-a582030b28c7"
      },
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "Module signature does not match saved state dict",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [9], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mapps\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m ResNet9_2\n\u001b[1;32m      3\u001b[0m differnt_model \u001b[39m=\u001b[39m ResNet9_2(device\u001b[39m=\u001b[39mndl\u001b[39m.\u001b[39mcpu())\n\u001b[0;32m----> 5\u001b[0m ndl\u001b[39m.\u001b[39;49mload_state_dict(differnt_model, \u001b[39m'\u001b[39;49m\u001b[39mweights.npy\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
            "File \u001b[0;32m~/projects/hw4/python/needle/save_load.py:44\u001b[0m, in \u001b[0;36mload_state_dict\u001b[0;34m(module, filename)\u001b[0m\n\u001b[1;32m     41\u001b[0m save_dict \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(filename, allow_pickle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     43\u001b[0m \u001b[39m# Check if the signature of the loaded module matches the saved state dict\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[39massert\u001b[39;00m save_dict[\u001b[39m'\u001b[39m\u001b[39msignature\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mstr\u001b[39m(module\u001b[39m.\u001b[39mid()), \u001b[39m\"\u001b[39m\u001b[39mModule signature does not match saved state dict\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     46\u001b[0m \u001b[39m# Check if the device of the loaded module matches the saved state dict\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[39massert\u001b[39;00m save_dict[\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mstr\u001b[39m(module\u001b[39m.\u001b[39mdevice), \u001b[39m\"\u001b[39m\u001b[39mModule device does not match saved state dict\u001b[39m\u001b[39m\"\u001b[39m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Module signature does not match saved state dict"
          ]
        }
      ],
      "source": [
        "from apps.models import ResNet9_2\n",
        "\n",
        "differnt_model = ResNet9_2(device=ndl.cpu())\n",
        "\n",
        "ndl.load_state_dict(differnt_model, 'weights.npy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ4MlZRxkch5"
      },
      "source": [
        "And similarly, we test loading to a different device."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpulsT20kch5",
        "outputId": "e2f1ce10-e63f-408e-e559-081af30661ed"
      },
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "Module device does not match saved state dict",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m cuda_model \u001b[39m=\u001b[39m ResNet9(device\u001b[39m=\u001b[39mndl\u001b[39m.\u001b[39mcuda())\n\u001b[0;32m----> 3\u001b[0m ndl\u001b[39m.\u001b[39;49mload_state_dict(cuda_model, \u001b[39m'\u001b[39;49m\u001b[39mweights.npy\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
            "File \u001b[0;32m~/projects/hw4/python/needle/save_load.py:47\u001b[0m, in \u001b[0;36mload_state_dict\u001b[0;34m(module, filename)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39massert\u001b[39;00m save_dict[\u001b[39m'\u001b[39m\u001b[39msignature\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mstr\u001b[39m(module\u001b[39m.\u001b[39mid()), \u001b[39m\"\u001b[39m\u001b[39mModule signature does not match saved state dict\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     46\u001b[0m \u001b[39m# Check if the device of the loaded module matches the saved state dict\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m \u001b[39massert\u001b[39;00m save_dict[\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mstr\u001b[39m(module\u001b[39m.\u001b[39mdevice), \u001b[39m\"\u001b[39m\u001b[39mModule device does not match saved state dict\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m \u001b[39m# Load the state dict to the module\u001b[39;00m\n\u001b[1;32m     50\u001b[0m module\u001b[39m.\u001b[39mload_state_dict(save_dict[\u001b[39m'\u001b[39m\u001b[39mstate_dict\u001b[39m\u001b[39m'\u001b[39m])\n",
            "\u001b[0;31mAssertionError\u001b[0m: Module device does not match saved state dict"
          ]
        }
      ],
      "source": [
        "cuda_model = ResNet9(device=ndl.cuda())\n",
        "\n",
        "ndl.load_state_dict(cuda_model, 'weights.npy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZzm-OCTkch5"
      },
      "source": [
        "The last functionality we want to demonstrate in this section is model summary, which gives us an overview fo the model's architecture and the shape of its parameters. Similar functionality is also available in PyTorch and Tensorflow, which can be really handy for debugging.\n",
        "\n",
        "For demo purpose, we examine the summary of `ResNet9` and `ResNet9_2` models. And understand why the loading should fail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4zXhWCMkch5",
        "outputId": "7f6c2f2f-4de1-4f49-cfd4-701fdd5115aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{ 'ConvBN-1': { 'BatchNorm2d-1': {'bias': (16,), 'weight': (16,)},\n",
            "                'Conv-1': {'bias': (16,), 'weight': (7, 7, 3, 16)},\n",
            "                'ReLU-1': {}},\n",
            "  'ConvBN-2': { 'BatchNorm2d-1': {'bias': (32,), 'weight': (32,)},\n",
            "                'Conv-1': {'bias': (32,), 'weight': (3, 3, 16, 32)},\n",
            "                'ReLU-1': {}},\n",
            "  'ConvBN-3': { 'BatchNorm2d-1': {'bias': (64,), 'weight': (64,)},\n",
            "                'Conv-1': {'bias': (64,), 'weight': (3, 3, 32, 64)},\n",
            "                'ReLU-1': {}},\n",
            "  'ConvBN-4': { 'BatchNorm2d-1': {'bias': (128,), 'weight': (128,)},\n",
            "                'Conv-1': {'bias': (128,), 'weight': (3, 3, 64, 128)},\n",
            "                'ReLU-1': {}},\n",
            "  'Flatten-1': {},\n",
            "  'Linear-1': {'bias': (1, 128), 'weight': (128, 128)},\n",
            "  'Linear-2': {'bias': (1, 10), 'weight': (128, 10)},\n",
            "  'ReLU-1': {},\n",
            "  'Residual-1': { 'Sequential-1': { 'ConvBN-1': { 'BatchNorm2d-1': { 'bias': ( 32,),\n",
            "                                                                     'weight': ( 32,)},\n",
            "                                                  'Conv-1': { 'bias': (32,),\n",
            "                                                              'weight': ( 3,\n",
            "                                                                          3,\n",
            "                                                                          32,\n",
            "                                                                          32)},\n",
            "                                                  'ReLU-1': {}},\n",
            "                                    'ConvBN-2': { 'BatchNorm2d-1': { 'bias': ( 32,),\n",
            "                                                                     'weight': ( 32,)},\n",
            "                                                  'Conv-1': { 'bias': (32,),\n",
            "                                                              'weight': ( 3,\n",
            "                                                                          3,\n",
            "                                                                          32,\n",
            "                                                                          32)},\n",
            "                                                  'ReLU-1': {}}}},\n",
            "  'Residual-2': { 'Sequential-1': { 'ConvBN-1': { 'BatchNorm2d-1': { 'bias': ( 128,),\n",
            "                                                                     'weight': ( 128,)},\n",
            "                                                  'Conv-1': { 'bias': (128,),\n",
            "                                                              'weight': ( 3,\n",
            "                                                                          3,\n",
            "                                                                          128,\n",
            "                                                                          128)},\n",
            "                                                  'ReLU-1': {}},\n",
            "                                    'ConvBN-2': { 'BatchNorm2d-1': { 'bias': ( 128,),\n",
            "                                                                     'weight': ( 128,)},\n",
            "                                                  'Conv-1': { 'bias': (128,),\n",
            "                                                              'weight': ( 3,\n",
            "                                                                          3,\n",
            "                                                                          128,\n",
            "                                                                          128)},\n",
            "                                                  'ReLU-1': {}}}}}\n"
          ]
        }
      ],
      "source": [
        "_ = model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-_1FHcukch5",
        "outputId": "6c42d169-0f74-41e9-86b0-70fd0156a585"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{ 'ConvBN-1': { 'BatchNorm2d-1': {'bias': (16,), 'weight': (16,)},\n",
            "                'Conv-1': {'bias': (16,), 'weight': (7, 7, 3, 16)},\n",
            "                'ReLU-1': {}},\n",
            "  'ConvBN-2': { 'BatchNorm2d-1': {'bias': (32,), 'weight': (32,)},\n",
            "                'Conv-1': {'bias': (32,), 'weight': (3, 3, 16, 32)},\n",
            "                'ReLU-1': {}},\n",
            "  'ConvBN-3': { 'BatchNorm2d-1': {'bias': (64,), 'weight': (64,)},\n",
            "                'Conv-1': {'bias': (64,), 'weight': (3, 3, 32, 64)},\n",
            "                'ReLU-1': {}},\n",
            "  'ConvBN-4': { 'BatchNorm2d-1': {'bias': (64,), 'weight': (64,)},\n",
            "                'Conv-1': {'bias': (64,), 'weight': (3, 3, 64, 64)},\n",
            "                'ReLU-1': {}},\n",
            "  'Flatten-1': {},\n",
            "  'Linear-1': {'bias': (1, 64), 'weight': (64, 64)},\n",
            "  'Linear-2': {'bias': (1, 10), 'weight': (64, 10)},\n",
            "  'ReLU-1': {},\n",
            "  'Residual-1': { 'Sequential-1': { 'ConvBN-1': { 'BatchNorm2d-1': { 'bias': ( 32,),\n",
            "                                                                     'weight': ( 32,)},\n",
            "                                                  'Conv-1': { 'bias': (32,),\n",
            "                                                              'weight': ( 3,\n",
            "                                                                          3,\n",
            "                                                                          32,\n",
            "                                                                          32)},\n",
            "                                                  'ReLU-1': {}},\n",
            "                                    'ConvBN-2': { 'BatchNorm2d-1': { 'bias': ( 32,),\n",
            "                                                                     'weight': ( 32,)},\n",
            "                                                  'Conv-1': { 'bias': (32,),\n",
            "                                                              'weight': ( 3,\n",
            "                                                                          3,\n",
            "                                                                          32,\n",
            "                                                                          32)},\n",
            "                                                  'ReLU-1': {}}}},\n",
            "  'Residual-2': { 'Sequential-1': { 'ConvBN-1': { 'BatchNorm2d-1': { 'bias': ( 64,),\n",
            "                                                                     'weight': ( 64,)},\n",
            "                                                  'Conv-1': { 'bias': (64,),\n",
            "                                                              'weight': ( 3,\n",
            "                                                                          3,\n",
            "                                                                          64,\n",
            "                                                                          64)},\n",
            "                                                  'ReLU-1': {}},\n",
            "                                    'ConvBN-2': { 'BatchNorm2d-1': { 'bias': ( 64,),\n",
            "                                                                     'weight': ( 64,)},\n",
            "                                                  'Conv-1': { 'bias': (64,),\n",
            "                                                              'weight': ( 3,\n",
            "                                                                          3,\n",
            "                                                                          64,\n",
            "                                                                          64)},\n",
            "                                                  'ReLU-1': {}}}}}\n"
          ]
        }
      ],
      "source": [
        "_ = differnt_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WWdo7qnkch6"
      },
      "source": [
        "If we look at `Residual-2.Sequential-1.ConvBN-1.BatchNorm2d-1`, we coudl see that  `ResNet9` has 128 channels in the first layer, while `ResNet9_2` has 64 channels. This is why the loading should fail."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JD9Zc7pZkch6"
      },
      "source": [
        "## 2 Port ONNX models to NEEDLE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuNoJVcJkch6"
      },
      "source": [
        "Due to the lack of training optimization (like operator optimization, distributed training), it's often hard to train a large scale model for multiple epochs on Needle directly. In order to enable Needle to run inference on large scale model, we support Needle to load pre-trained model from other ML framework like PyTorch, Tensorflow, Caffe etc. \n",
        "\n",
        "Instead of building seperate model loader for each ML framework individually, we only implement the convertion from ONNX to Needle. ONNX is a widely used open format supporting model transfer between multiple ML frameworks like PyTorch, Tensorflow, Caffe etc, thus could be a good intermediate to bridge the convertion between Needle and other common ML frameworks.\n",
        "\n",
        "In order to load ONNX model to Needle. We need to: 1). Load the protocol buffer stored in Onnx model file and use a parser to extract each module (we call it node), their input / output variable names, and weights. 2). Using the intermediate nodes, we can construct a graph, and use **topological sort** to iterate through the graph to get the order of module initialization and inference. 3). We transfer each of the intermediate node to Needle.nn modules, and construct the target Needle model from these modules dynamically.\n",
        "\n",
        "We will introduce each step in detail below.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cY4ngHzO3it"
      },
      "source": [
        "### Term Definition\n",
        "*   node: intermediate representation object extracted from ONNX. Its input/output are variable names defined in Onnx\n",
        "*   module: needle.nn objects. Its input/output are tensors\n",
        "*   model input: input tensor for the entire model during forward propagation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qwUzGxaOz07"
      },
      "source": [
        "\n",
        "### Description\n",
        "#### Parse ONNX module to Dictionary\n",
        "ONNX uses a custom format to store models. Specifically, onnx.node store all the operation graph between each module (like input, output, attribute value, and name of weight and bias), and onnx.initializer store all the values of weight and bias corredsponding to the name in onnx.node. \n",
        "\n",
        "Thus, likewise, we construct some object to store the value parsed from ONNX model. For which OnnxNode class is similar to what onnx.node is doing, which record all the connection between different data, while OnnxData is similar to onnx.data, which store all the actual value of data.\n",
        "\n",
        "Moreover, we design classes inheriting from OnnxNode for each layer and operator in the onnx.node, please refer to needle/onnx_dict.py for detail.\n",
        "\n",
        "```python\n",
        "class OnnxNode:\n",
        "    def __init__(self, att_dict) -> None:\n",
        "        self.name = att_dict['name']\n",
        "        self.inputs = att_dict['inputs']\n",
        "        self.indegree = len(self.inputs)\n",
        "        for input_name in self.inputs:\n",
        "            if \"data\" in input_name:\n",
        "                self.indegree -= 1\n",
        "        self.output: str = att_dict['output']\n",
        "\n",
        "class OnnxData:\n",
        "    def __init__(self, **kwargs) -> None:\n",
        "        self.name = kwargs['name']\n",
        "        self.dtype = kwargs['dtype']\n",
        "        self.category = \"Initializer\"   \n",
        "        self.data: np.array = kwargs['data']\n",
        "        self.dims: list =kwargs['dims']\n",
        "\n",
        "class ConvOpNode(OnnxNode):\n",
        "    def __init__(self, att_dict) -> None:\n",
        "        super().__init__(att_dict)\n",
        "        \n",
        "        # attribures\n",
        "        self.dilations = att_dict[\"dilations\"]\n",
        "        self.group = att_dict[\"group\"]\n",
        "        self.kernel_shape = att_dict[\"kernel_shape\"]\n",
        "        self.padding = att_dict[\"pads\"]\n",
        "        self.strides = att_dict[\"strides\"]\n",
        "        \n",
        "        # data field\n",
        "        self.X_name = att_dict[\"X_name\"]\n",
        "        self.Y_name = att_dict[\"Y_name\"]\n",
        "        self.W_name = att_dict[\"W_name\"]\n",
        "        self.W: OnnxData = att_dict[\"W_data\"]\n",
        "        self.use_bias = False\n",
        "        if \"B_name\" in att_dict:\n",
        "            self.use_bias = True\n",
        "            self.B_name = att_dict[\"B_name\"]\n",
        "            self.B: OnnxData = att_dict[\"B_data\"]\n",
        "\n",
        "        self.out_channels, self.in_channels, _, _ = self.W.dims\n",
        "        \n",
        "class BatchNorm2DNode(OnnxNode):\n",
        "    def __init__(self, att_dict) -> None:\n",
        "        super().__init__(att_dict)\n",
        "\n",
        "        # attribures\n",
        "        self.eps = att_dict[\"epsilon\"]\n",
        "        self.momentum = att_dict[\"momentum\"]\n",
        "        self.spatial = att_dict[\"spatial\"]\n",
        "\n",
        "        # data field\n",
        "        self.X_name = att_dict[\"X_name\"]\n",
        "        self.gamma_name = att_dict[\"gamma_name\"]\n",
        "        self.gamma: OnnxData = att_dict[\"gamma_data\"]\n",
        "        self.beta_name = att_dict[\"beta_name\"]\n",
        "        self.beta: OnnxData = att_dict[\"beta_data\"]\n",
        "        self.running_mean_name = att_dict[\"running_mean_name\"]\n",
        "        self.running_mean: OnnxData = att_dict[\"running_mean_data\"]\n",
        "        self.running_var_name = att_dict[\"running_var_name\"]\n",
        "        self.running_var: OnnxData = att_dict[\"running_var_data\"]\n",
        "        self.Y_name = att_dict[\"Y_name\"]\n",
        "\n",
        "        self.dim = self.gamma.dims[0]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-TNwL7skch6"
      },
      "source": [
        "#### Build a Graph from ONNX Nodes\n",
        "Given a list intermediate nodes, we build a graph by finding the input/output variable dependency of each node, and get the order to sequentially execute each Needle module constructed from node, only when their input variables are ready. Each node can have multiple input variables, after subtracting the number of model input, the rest are variables calculated by other nodes, we call this number indegree of a node. We use a Python dictionary (onnx_input_dict) to store the nodes which require the variable name (key) as input.\n",
        "\n",
        "We first push the node with 0 indegree (only taking model input) into a queue, and get a list of its output variables. For each output, we subtract the indegree of subsequent nodes using this output by 1, and push the node to queue if its indegree equals to 0, meaning that all input variables to this node are already calculated. This process is continued until the queue is empty, indicating all the nodes in this graph are processed.\n",
        "\n",
        "Please refer to apps/models.py for detailed implementation:\n",
        "\n",
        "```python\n",
        "class ModelFromOnnx(nn.Module):\n",
        "    \"\"\"Needle model that is built from a list of interconnected Onnx nodes\"\"\"\n",
        "    def __init__(self, onnx_node_list, device=None, dtype=\"float32\"):\n",
        "        super().__init__()\n",
        "        self.modules = []  # list of Needle modules in the model\n",
        "        self.modules_input = []  # input variable names of each module\n",
        "        self.onnx_output_list = []  # map node to output values\n",
        "        \n",
        "        onnx_input_dict = {}  # map input variable names to nodes\n",
        "        next_node = []  # queue for next module to initialize\n",
        "        for node in onnx_node_list:\n",
        "            if node.indegree == 0:\n",
        "                next_node.append(node)\n",
        "            for node_input in node.inputs:\n",
        "                if node_input in onnx_input_dict:\n",
        "                    onnx_input_dict[node_input].append(node)\n",
        "                else:\n",
        "                    onnx_input_dict[node_input] = [node]\n",
        "        \n",
        "        while len(next_node) > 0:\n",
        "            node = next_node.pop(0)\n",
        "            ...\n",
        "\n",
        "            self.modules.append(next_module)\n",
        "            self.modules_input.append(node.inputs)\n",
        "            \n",
        "            self.onnx_output_list.append([])\n",
        "            for node_out in node.outputs:\n",
        "                self.onnx_output_list[-1].append(node_out)  # store output variable names\n",
        "                \n",
        "                for i, subsequent_node in enumerate(onnx_input_dict.get(node_out, [])):\n",
        "                    # check all nodes that take current node's output as input\n",
        "                    onnx_input_dict[node_out][i].indegree -= 1\n",
        "                    if onnx_input_dict[node_out][i].indegree == 0:\n",
        "                        next_node.append(subsequent_node)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDGIAFkfkch6"
      },
      "source": [
        "#### Construct NEEDLE Model from ONNX nodes\n",
        "Finally, we initialize needle.nn modules from ONNX nodes in the order from previous step, as well as creating weight tensors from OnnxData and replacing the original weight tensors stored in the module. Here we show the initialzation of several layers and operators, please refer to apps/models.py for full implementation:\n",
        "\n",
        "```python\n",
        "while len(next_node) > 0:\n",
        "    node = next_node.pop(0)\n",
        "    # initialize the corresponding nn module from onnx node with attributes, construct and load weight tensors if needed\n",
        "    if isinstance(node, onnx.ConvOpNode):\n",
        "        next_module = nn.Conv(node.in_channels, node.out_channels, node.kernel_shape[0], \n",
        "                                node.strides[0], bias=node.use_bias, device=device, dtype=dtype)\n",
        "        if node.use_bias:\n",
        "            next_module.load_weights(ndl.Tensor(ndl.NDArray(node.W.data.transpose(2,3,1,0)), device=device, dtype=dtype),\n",
        "                                        ndl.Tensor(ndl.NDArray(node.B.data), device=device, dtype=dtype))\n",
        "        else:\n",
        "            next_module.load_weights(ndl.Tensor(ndl.NDArray(node.W.data.transpose(2,3,1,0)), device=device, dtype=dtype))\n",
        "    elif isinstance(node, onnx.ReLUNode):\n",
        "        next_module = nn.ReLU()\n",
        "    elif isinstance(node, onnx.MaxPoolNode):\n",
        "        next_module = nn.MaxPool2d(node.kernel_shape[0], node.strides[0], node.padding[0])\n",
        "    elif isinstance(node, onnx.RNNNode):\n",
        "        next_module = nn.RNN(node.input_size, node.hidden_size, nonlinearity=node.activation, device=device, dtype=dtype)\n",
        "        next_module.load_weights(W_ih=ndl.Tensor(ndl.NDArray(np.squeeze(node.W_ih).T), device=device, dtype=dtype),\n",
        "                                    W_hh=ndl.Tensor(ndl.NDArray(np.squeeze(node.W_hh).T), device=device, dtype=dtype),\n",
        "                                    b_ih=ndl.Tensor(ndl.NDArray(np.squeeze(node.B)[:node.hidden_size]), device=device, dtype=dtype),\n",
        "                                    b_hh=ndl.Tensor(ndl.NDArray(np.squeeze(node.B)[node.hidden_size:]), device=device, dtype=dtype))\n",
        "    elif isinstance(node, onnx.SqueezeNode):\n",
        "        next_module = nn.Squeeze(axes=node.axes)\n",
        "```\n",
        "\n",
        "During each step of forward propagation, we store the output Tensors of the executed module in a Python dictionary (module_io_vals), and then construct a list of input Tensors for the next module from either the dictionary, or model input X.\n",
        "\n",
        "```python\n",
        "def forward(self, x):\n",
        "    module_io_vals = {}  # store the output of each step\n",
        "    for step, (module, input_ids) in enumerate(zip(self.modules, self.modules_input)):\n",
        "        # construct module input from either module_io_vals (using variable name as key), or use model input\n",
        "        inputs = [(module_io_vals[id] if not (\"data\" in id or \"initial_\" in id) else x) for id in input_ids]\n",
        "        out = module(*inputs)\n",
        "        if type(out) == tuple:  # a tuple of tensors (RNN case)\n",
        "            assert len(self.onnx_output_list[step]) == len(out)\n",
        "            for out_tensor_name, out_tensor in zip(self.onnx_output_list[step], out):\n",
        "                module_io_vals[out_tensor_name] = out_tensor\n",
        "        else:  # single tensor\n",
        "            assert len(self.onnx_output_list[step]) == 1\n",
        "            module_io_vals[self.onnx_output_list[step][0]] = out\n",
        "    \n",
        "    return out\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mD1wf9vikch7"
      },
      "source": [
        "### Demo\n",
        "Our model convertion supports loading CNN and RNN, which we implemented in NEEDLE in HW4. In this demo, we load an ONNX model, convert it to the equivalent NEEDLE model, inference the two models and compare the result Tensor. Similar to testers in Homeworks, a close to 0 difference means our convertion is correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Fy2gGYOokch7",
        "outputId": "6f5af896-e95b-404b-c302-871fb17f7a3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "<module 'needle.backend_ndarray' from '/home/jeremy/Master/needle-pretrain/./python/needle/backend_ndarray/__init__.py'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jeremy/anaconda3/envs/course_16824/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('./python')\n",
        "import numpy as np\n",
        "import needle as ndl\n",
        "\n",
        "import needle.onnx_parser as onnx_parser\n",
        "sys.path.append('.')\n",
        "from apps.models import ModelFromOnnx\n",
        "\n",
        "import onnx\n",
        "import onnxruntime\n",
        "from onnx2torch import convert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpLROHCNmUcs"
      },
      "source": [
        "First, we load an ONNX ResNet-50 model consisting of Conv, pooling, ReLU and residual connection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Z5dQStUmkch7"
      },
      "outputs": [],
      "source": [
        "\n",
        "onnx_model = onnx.load(\"models/resnet50.onnx\")\n",
        "node_list = onnx_model.graph.node\n",
        "initializer_list = onnx_model.graph.initializer\n",
        "init_dict = onnx_parser.load_initializer(initializer_list)\n",
        "onnx_node_list = onnx_parser.load_node(node_list,init_dict)\n",
        "assert len(onnx_node_list) == len(node_list)\n",
        "\n",
        "# inferece Needle model transferred from Onnx\n",
        "device = ndl.cpu()\n",
        "model = ModelFromOnnx(onnx_node_list, device=device)\n",
        "test_input_np = np.random.rand(1, 3, 224, 224).astype('float32')\n",
        "ndl_input = ndl.Tensor(ndl.NDArray(test_input_np), device=device)\n",
        "test_out = model(ndl_input)\n",
        "\n",
        "# inference Onnx model\n",
        "session = onnxruntime.InferenceSession(\"models/resnet50.onnx\")\n",
        "input_name = session.get_inputs()[0].name\n",
        "output_name = session.get_outputs()[0].name\n",
        "onnx_out = session.run([output_name], {input_name: test_input_np})\n",
        "onnx_out_np = np.squeeze(np.array(onnx_out), axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gkt_lk4Bkch7"
      },
      "source": [
        "As we can see, the NEEDLE model from ONNX produced the same output as the ONNX model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7qTtLsSMkch7",
        "outputId": "c250cce4-dab6-4c0a-c464-d359b71bbebf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8.583069e-06\n"
          ]
        }
      ],
      "source": [
        "\n",
        "assert test_out.shape == onnx_out_np.shape\n",
        "print(np.max(np.abs(test_out.numpy() - onnx_out_np)))\n",
        "assert np.allclose(test_out.numpy(), onnx_out_np, atol=1e-05)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJeshSMPkch7"
      },
      "source": [
        "Next, we load an ONNX RNN model consisting of embedding, RNN, reshaping and linear layer, which also produces the same result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "os-mO4STkch8"
      },
      "outputs": [],
      "source": [
        "onnx_model = onnx.load(\"models/rnn.onnx\")\n",
        "node_list = onnx_model.graph.node\n",
        "initializer_list = onnx_model.graph.initializer\n",
        "init_dict = onnx_parser.load_initializer(initializer_list)\n",
        "onnx_node_list = onnx_parser.load_node(node_list, init_dict)\n",
        "\n",
        "# inferece Needle model transferred from Onnx\n",
        "device = ndl.cpu()\n",
        "model = ModelFromOnnx(onnx_node_list, device=device)\n",
        "test_input_np = np.random.randint(0, 16, (5, 1)).astype('long')\n",
        "ndl_input = ndl.Tensor(ndl.NDArray(test_input_np), device=device)\n",
        "test_out = model(ndl_input)\n",
        "\n",
        "# inference Onnx model\n",
        "session = onnxruntime.InferenceSession(\"models/rnn.onnx\")\n",
        "input_name = session.get_inputs()[0].name\n",
        "output_name = session.get_outputs()[0].name\n",
        "onnx_out = session.run([output_name], {input_name: test_input_np})\n",
        "onnx_out_np = np.squeeze(np.array(onnx_out), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KHQO1lwlkch8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.1920929e-07\n"
          ]
        }
      ],
      "source": [
        "assert test_out.shape == onnx_out_np.shape\n",
        "print(np.max(np.abs(test_out.numpy() - onnx_out_np)))\n",
        "assert np.allclose(test_out.numpy(), onnx_out_np, atol=1e-05)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATPLxJmfkch8"
      },
      "source": [
        "## Appendix \n",
        "In this section, we breifly discuss how to convert a PyTorch model to ONNX model. Although our focus of this project is to convert ONNX model to Needle, ONNX are mostly used for moving models  between different tools and frameworks for training, optimizing, and deploying them instead of building a model from scratch. Thus, for the sake of completeness, we will breifly discuss how to build a PyTorch model and convert it to ONNX model. Here, we demonstrate with two examples, one is a pretrained ResNet model offered by torchvision, and the other is a simple RNN model we build from scratch. Note that this section heavily relies on the official PyTorch documentation.\n",
        "\n",
        "### Using Pretrained Model from torchvision\n",
        "Here we demonstrate how to use a pretrained ResNet18 model from torchvision. The model is pretrained on the ImageNet dataset.\n",
        "\n",
        "```python\n",
        "# import the resnet18 model from PyTorch's torchvision module\n",
        "from torchvision.models import resnet18 \n",
        "import torch\n",
        "\n",
        "# create a resnet18 model and load it with pre-trained weights\n",
        "model = resnet18(pretrained=True) \n",
        "\n",
        "# Specify the input and output names of the onnx model\n",
        "input_names = ['data'] \n",
        "output_names = ['output']\n",
        "\n",
        "# create a dummy input tensor used to trace the model\n",
        "dummy_input = torch.randn(1, 3, 224, 224, device='cpu') \n",
        "\n",
        "# export the model to ONNX format\n",
        "torch.onnx.export(model, dummy_input, 'resnet18.onnx', verbose=True, input_names=input_names, output_names=output_names) \n",
        "```\n",
        "\n",
        "### Build a model from scratch\n",
        "The process of building a model from scratch is similar to the process of importing a pretrained model from torchvision. We define a simple RNN model with specified embedding size, output size, hidden size and number of layers\n",
        "The model is composed of an embedding layer, an RNN layer and a fully connected layer, similar to what we built in hw4\n",
        "\n",
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class SequenceModel(nn.Module):\n",
        "    def __init__(self, embedding_size, output_size, hidden_size, num_layers=1, device='cpu', dtype=torch.float32):\n",
        "        self.embedding_size = embedding_size\n",
        "        self.output_size = output_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.device = device\n",
        "        self.dtype = dtype\n",
        "\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
        "        self.rnn = nn.RNN(embedding_size, hidden_size, num_layers=num_layers, bidirectional=False, dropout=0)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        seq_len, batch_size = x.shape\n",
        "        x = self.embedding(x)\n",
        "        x, h = self.rnn(x)\n",
        "\n",
        "        x = x.view(seq_len * batch_size, -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Instantiate the model we just defined\n",
        "model = SequenceModel(embedding_size=10, output_size=16, hidden_size=8, device='cpu')\n",
        "\n",
        "# Create a dummy input tensor used to trace the model\n",
        "x = torch.randint(0, 16, (5, 1), dtype=torch.long)\n",
        "\n",
        "# Specify the input and output names of the onnx model\n",
        "input_names = ['data']\n",
        "output_names = ['output']\n",
        "\n",
        "# export the model to ONNX format\n",
        "torch.onnx.export(model, x, 'rnn.onnx', verbose=True, input_names=input_names, output_names=output_names)\n",
        "```\n",
        "\n",
        "We have verfied with multiple models that the exported ONNX model produce the same output as the original PyTorch model, which ensures that our corresponding Needle model will produce the same output as the original PyTorch model given it has the same output as the ONNX model. Since not a main focus of the project, the code for exporting ONNX model is not part of the submission."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bPcr6xSkch8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xsPaIoHkch8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0MZdZSikch8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 ('course_16824')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "f9935fb49fb362de606360772d297eefaa5a37b30e650da9f346c5744a879a98"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
